{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Q/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import  ChatGroq\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "groq_api_key=\"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\"\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"mixtral-8x7b-32768\",\n",
    "    temperature=0.4,\n",
    "    max_retries=2,\n",
    "    #max_tokens=None, # Removing this as it might cause issues, let the model decide\n",
    "    api_key=groq_api_key\n",
    ")\n",
    "\n",
    "# Custom Prompt\n",
    "custom_prompt_template_for_chatbot = \"\"\"\n",
    "You are a knowledgeable assistant specializing in Data Science and Artificial Intelligence (AI).\n",
    "\n",
    "Your primary objective is to assist students by providing clear, concise, and accurate answers to their questions specifically related to Data Science and AI. This includes, but is not limited to, the following topics:\n",
    "- Programming languages and tools: Python, SQL (MySQL, SQLite, MongoDB)\n",
    "- Data visualization tools: Power BI, Tableau\n",
    "- Statistical concepts and methodologies\n",
    "- Machine Learning (ML) techniques and frameworks\n",
    "- MLFlow for managing machine learning workflows\n",
    "- Containerization with Docker\n",
    "- Deep Learning concepts and frameworks\n",
    "- Natural Language Processing (NLP)\n",
    "- Generative AI technologies\n",
    "- Skills required for a career in Data Science and AI\n",
    "\n",
    "When responding, ensure that your answers are focused and straightforward, avoiding unnecessary details. If users ask complex questions, break down your responses into manageable parts and provide step-by-step explanations when needed.\n",
    "\n",
    "Always be polite and encouraging, ensuring that you provide accurate information at all times.\n",
    "\n",
    "Remember previous exchanges in the conversation to provide better context for your responses.\n",
    "\n",
    "If a question is asked that falls outside the realm of Data Science and AI or does not relate to the topics mentioned above, respond with a polite message indicating that the question is unrelated. For example: \"I'm sorry, but that topic is outside the scope of Data Science and AI. I'm unable to provide an answer.\"\n",
    "\n",
    "Question: {history} Current question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=custom_prompt_template_for_chatbot,\n",
    "    input_variables=[\"history\", \"question\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize memory\n",
    "memory = ConversationBufferMemory(memory_key=\"history\", input_key=\"question\")\n",
    "\n",
    "\n",
    "# Create chain with memory\n",
    "qa_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "def handle_qna(user_input):\n",
    "    \"\"\"\n",
    "    Handles user queries for Q&A functionality.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = qa_chain.run(user_input)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while processing your question: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML stands for Machine Learning, a subset of Artificial Intelligence (AI) that focuses on the development of algorithms and statistical models that enable computers to perform tasks without explicit programming. Instead, these systems learn and improve from experience, data, and patterns. Machine Learning techniques are used in a wide range of applications, from recommendation systems and fraud detection to self-driving cars and natural language processing. There are three main types of Machine Learning: supervised learning, unsupervised learning, and reinforcement learning.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle_qna(\"what is ML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning (ML) is an exciting and rapidly growing field within Data Science and Artificial Intelligence (AI), offering numerous career opportunities. Here are some reasons why you should consider ML as a career option:\n",
      "\n",
      "1. High demand: ML engineers and data scientists are in high demand across various industries, such as healthcare, finance, technology, and retail. Companies are increasingly relying on ML to make data-driven decisions, optimize processes, and develop innovative products and services.\n",
      "\n",
      "2. Competitive salary: ML professionals often receive competitive salaries due to the high demand and complexity of the role. According to Glassdoor, the average salary for a Machine Learning Engineer in the United States is around $114,000 per year.\n",
      "\n",
      "3. Dynamic and challenging work: ML involves working with complex algorithms, large datasets, and cutting-edge technologies. This dynamic and challenging work environment keeps professionals engaged and constantly learning new skills.\n",
      "\n",
      "4. Versatility: ML skills can be applied to a wide range of industries and job roles. For example, you can work as a research scientist, data analyst, ML engineer, or AI architect, among others.\n",
      "\n",
      "5. Strong job growth: The job market for ML professionals is expected to grow significantly in the coming years. According to the U.S. Bureau of Labor Statistics, employment of data scientists and mathematical science occupations is projected to grow 33% from 2019 to 2029, much faster than the average for all occupations.\n",
      "\n",
      "6. Opportunities for innovation: ML professionals have the opportunity to work on groundbreaking projects that can impact society and change the way we live, work, and interact with technology.\n",
      "\n",
      "7. Constant learning and development: ML is a rapidly evolving field, and professionals must stay up-to-date with the latest trends, techniques, and tools. This continuous learning and development keep the job interesting and engaging.\n",
      "\n",
      "8. Collaborative work environment: ML professionals often work in cross-functional teams, collaborating with data scientists, software engineers, domain experts, and other professionals. This collaborative work environment fosters creativity, knowledge sharing, and skill development.\n",
      "\n",
      "In summary, ML offers numerous career opportunities, competitive salaries, dynamic work environments, and the chance to work on innovative projects. If you enjoy working with data, algorithms, and cutting-edge technologies, ML could be an excellent career option for you.\n"
     ]
    }
   ],
   "source": [
    "print(handle_qna(\"why i need to see Ml as a career option\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Set Reminders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import threading\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Global dictionary to store active reminders\n",
    "reminders = []\n",
    "conversation_context = {}\n",
    "\n",
    "def normalize_time(user_input):\n",
    "    \"\"\"\n",
    "    Normalize unconventional time inputs into a valid 12-hour HH:MM AM/PM format.\n",
    "    For example:\n",
    "    - '914pm' -> '09:14 PM'\n",
    "    - '915pm' -> '09:15 PM'\n",
    "    - '9pm' -> '09:00 PM'\n",
    "    \"\"\"\n",
    "    # Extract numbers and AM/PM\n",
    "    match = re.match(r'(\\d{1,4})(AM|PM|am|pm)?', user_input, re.IGNORECASE)\n",
    "    if not match:\n",
    "        return None  # Invalid input\n",
    "    \n",
    "    raw_time = match.group(1)  # Extract the numeric part\n",
    "    period = match.group(2).upper() if match.group(2) else \"PM\"  # Default to PM if not provided\n",
    "\n",
    "    # Handle different lengths of the raw_time\n",
    "    if len(raw_time) == 1 or len(raw_time) == 2:  # e.g., '9' or '12'\n",
    "        hour = int(raw_time)\n",
    "        minute = 0\n",
    "    elif len(raw_time) == 3:  # e.g., '914' -> hour: 9, minute: 14\n",
    "        hour = int(raw_time[0])\n",
    "        minute = int(raw_time[1:])\n",
    "    elif len(raw_time) == 4:  # e.g., '0915' or '915' -> hour: 9, minute: 15\n",
    "        hour = int(raw_time[:2])\n",
    "        minute = int(raw_time[2:])\n",
    "    else:\n",
    "        return None  # Invalid input length\n",
    "\n",
    "    # Adjust hour and minute for valid time ranges\n",
    "    while minute >= 60:\n",
    "        hour += 1\n",
    "        minute -= 60\n",
    "\n",
    "    # Convert to 12-hour format\n",
    "    if hour > 12:\n",
    "        hour %= 12\n",
    "    if hour == 0:\n",
    "        hour = 12\n",
    "\n",
    "    # Format into HH:MM AM/PM\n",
    "    try:\n",
    "        normalized_time = datetime.strptime(f\"{hour}:{minute:02d} {period}\", \"%I:%M %p\")\n",
    "        return normalized_time.strftime(\"%I:%M %p\")\n",
    "    except ValueError:\n",
    "        return None  # Invalid input after adjustments\n",
    "\n",
    "# Reminder Handler\n",
    "def handle_reminder(user_input):\n",
    "    \"\"\"\n",
    "    Handles setting reminders interactively with the user.\n",
    "    \"\"\"\n",
    "    global conversation_context\n",
    "\n",
    "    # If there's a pending_action in conversation_context, continue that flow\n",
    "    if \"pending_action\" in conversation_context:\n",
    "        action = conversation_context.pop(\"pending_action\")\n",
    "        if action == \"set_reminder_time\":\n",
    "            # Normalize time input\n",
    "            normalized_time = normalize_time(user_input)\n",
    "            if not normalized_time:\n",
    "                return \"Invalid time format. Please provide the time in HH:MM AM/PM format (e.g., 02:30 PM).\"\n",
    "            conversation_context[\"reminder_time\"] = normalized_time\n",
    "            conversation_context[\"pending_action\"] = \"set_reminder_message\"\n",
    "            return \"What should I remind you about?\"\n",
    "        elif action == \"set_reminder_message\":\n",
    "            # Now we have time and message, we can set the reminder\n",
    "            reminder_time = conversation_context.pop(\"reminder_time\")\n",
    "            reminder_message = user_input\n",
    "            set_reminder(reminder_time, reminder_message)\n",
    "            return f\"Reminder set for {reminder_time} with message: '{reminder_message}'\"\n",
    "    else:\n",
    "        # Start the reminder setting process\n",
    "        conversation_context[\"pending_action\"] = \"set_reminder_time\"\n",
    "        return \"What time should I set the reminder for? (e.g., 02:30 PM)\"\n",
    "\n",
    "def set_reminder(reminder_time, message):\n",
    "    \"\"\"\n",
    "    Create a background thread that triggers at the exact reminder_time (12-hour format).\n",
    "    \"\"\"\n",
    "    def reminder_thread():\n",
    "        while True:\n",
    "            current_time = datetime.now().strftime(\"%I:%M %p\")  # 12-hour format\n",
    "            if current_time == reminder_time:\n",
    "                print(f\"\\nReminder: {message}\")\n",
    "                break\n",
    "            time.sleep(1)\n",
    "\n",
    "    reminders.append({\"time\": reminder_time, \"message\": message})\n",
    "    threading.Thread(target=reminder_thread, daemon=True).start()\n",
    "\n",
    "# Test Reminder Functionality\n",
    "# if __name__ == \"__main__\":\n",
    "#     conversation_context = {}  # Initialize global conversation context\n",
    "#     print(\"Welcome to the Reminder Module!\")\n",
    "#     print(\"You can interactively set reminders.\")\n",
    "\n",
    "#     while True:\n",
    "#         user_input = input(\"You: \").strip()\n",
    "#         if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "#             print(\"Goodbye!\")\n",
    "#             break\n",
    "#         response = handle_reminder(user_input)\n",
    "#         print(f\"Assistant: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##weather featcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather(location):\n",
    "    \"\"\"\n",
    "    Fetch the weather details for a given location using Open-Meteo.\n",
    "    \"\"\"\n",
    "    geocode_url = f\"https://geocoding-api.open-meteo.com/v1/search?name={location}\"\n",
    "\n",
    "    try:\n",
    "        # Fetch latitude and longitude\n",
    "        geocode_response = requests.get(geocode_url)\n",
    "        geocode_response.raise_for_status()\n",
    "        geocode_data = geocode_response.json()\n",
    "\n",
    "        if \"results\" not in geocode_data or len(geocode_data[\"results\"]) == 0:\n",
    "            return f\"Sorry, I couldn't find weather details for '{location}'. Please try another location.\"\n",
    "\n",
    "        latitude = geocode_data[\"results\"][0][\"latitude\"]\n",
    "        longitude = geocode_data[\"results\"][0][\"longitude\"]\n",
    "        location_name = geocode_data[\"results\"][0][\"name\"]\n",
    "\n",
    "        # Fetch weather details\n",
    "        weather_url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current_weather=true\"\n",
    "        weather_response = requests.get(weather_url)\n",
    "        weather_response.raise_for_status()\n",
    "        weather_data = weather_response.json()\n",
    "\n",
    "        if \"current_weather\" in weather_data:\n",
    "            current_weather = weather_data[\"current_weather\"]\n",
    "            temperature = current_weather[\"temperature\"]\n",
    "            windspeed = current_weather[\"windspeed\"]\n",
    "            weather_code = current_weather.get(\"weathercode\", -1)\n",
    "\n",
    "            weather_conditions = {\n",
    "                0: \"Clear sky\",\n",
    "                1: \"Mainly clear\",\n",
    "                2: \"Partly cloudy\",\n",
    "                3: \"Overcast\",\n",
    "                45: \"Foggy\",\n",
    "                48: \"Depositing rime fog\",\n",
    "                51: \"Light drizzle\",\n",
    "                53: \"Moderate drizzle\",\n",
    "                55: \"Dense drizzle\",\n",
    "                61: \"Slight rain\",\n",
    "                63: \"Moderate rain\",\n",
    "                65: \"Heavy rain\",\n",
    "                71: \"Slight snow\",\n",
    "                73: \"Moderate snow\",\n",
    "                75: \"Heavy snow\",\n",
    "                80: \"Rain showers\",\n",
    "                81: \"Moderate rain showers\",\n",
    "                82: \"Heavy rain showers\",\n",
    "                95: \"Thunderstorm\",\n",
    "                96: \"Thunderstorm with hail\",\n",
    "            }\n",
    "            weather_description = weather_conditions.get(weather_code, \"Unknown conditions\")\n",
    "\n",
    "            temperature_description = (\n",
    "                \"hot\" if temperature > 30 else \"cold\" if temperature < 15 else \"moderate\"\n",
    "            )\n",
    "\n",
    "            return (f\"The current weather in {location_name} is {weather_description} with a temperature of \"\n",
    "                    f\"{temperature}°C ({temperature_description}) and a windspeed of {windspeed} km/h.\")\n",
    "        else:\n",
    "            return \"Sorry, I couldn't fetch the weather details at this time.\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"An error occurred while fetching weather data: {e}\"\n",
    "\n",
    "def handle_weather(user_input):\n",
    "    \"\"\"\n",
    "    Handles weather-related queries interactively with the user.\n",
    "    \"\"\"\n",
    "    global current_functionality, conversation_context\n",
    "\n",
    "    # Directly fetch weather if functionality is already set to 'weather'\n",
    "    if current_functionality == \"weather\":\n",
    "        if user_input.lower() == \"exit\":\n",
    "            current_functionality = None\n",
    "            return \"Exited the weather functionality. How can I assist you next?\"\n",
    "        return fetch_weather(user_input.strip())\n",
    "\n",
    "    # Detect if location is already mentioned in the first input\n",
    "    if user_input.lower() in [\"weather\", \"weather update\", \"what's the weather outside\"]:\n",
    "        current_functionality = \"weather\"\n",
    "        return \"For which location would you like to get the weather?\"\n",
    "\n",
    "    # Assume the user input is a location on the first call\n",
    "    current_functionality = \"weather\"\n",
    "    return fetch_weather(user_input.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent for music\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "music_player = None  # Global music player\n",
    "\n",
    "# Initialize LLM for Music Query Processing\n",
    "llm_music = ChatGroq(\n",
    "    api_key=groq_api_key,\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Few-shot examples for music queries\n",
    "music_few_shot_examples = [\n",
    "    {\"input\": \"Play the latest song by Taylor Swift.\", \"query\": \"latest song by Taylor Swift\"},\n",
    "    {\"input\": \"I want to listen to some relaxing piano music.\", \"query\": \"relaxing piano music\"},\n",
    "    {\"input\": \"Play Pushpa 2 title song.\", \"query\": \"Pushpa 2 title song\"},\n",
    "    {\"input\": \"Find and play some jazz music.\", \"query\": \"jazz music\"},\n",
    "    {\"input\": \"Despacito song\", \"query\": \"Despacito song\"},\n",
    "    {\"input\": \"I want the title song from the movie Pushpa.\", \"query\": \"title song from the movie Pushpa\"},\n",
    "    {\"input\": \"Play the Devara Telugu movie title song.\", \"query\": \"Devara Telugu movie title song\"},\n",
    "    {\"input\": \"Play something classical.\", \"query\": \"classical music\"},\n",
    "    {\"input\": \"Can you find a remix of Shape of You?\", \"query\": \"Shape of You remix\"},\n",
    "    {\"input\": \"Play Arijit Singh's latest hit.\", \"query\": \"Arijit Singh latest hit song\"},\n",
    "    {\"input\": \"Find and play a calming meditation track.\", \"query\": \"calming meditation track\"},\n",
    "    {\"input\": \"I want to hear Bollywood romantic songs.\", \"query\": \"Bollywood romantic songs\"},\n",
    "    {\"input\": \"Play a workout playlist.\", \"query\": \"workout playlist\"},\n",
    "    {\"input\": \"Do you have any rock music?\", \"query\": \"rock music\"},\n",
    "    {\"input\": \"Find a Telugu devotional song for me.\", \"query\": \"Telugu devotional song\"},\n",
    "    {\"input\": \"Play Ed Sheeran's Perfect.\", \"query\": \"Ed Sheeran Perfect\"},\n",
    "    {\"input\": \"Play the background score of Interstellar.\", \"query\": \"Interstellar background score\"},\n",
    "    {\"input\": \"Can you play 'Kala Chashma'?\", \"query\": \"Kala Chashma song\"},\n",
    "    {\"input\": \"I want to listen to a live version of Rolling in the Deep.\", \"query\": \"live version of Rolling in the Deep\"},\n",
    "    {\"input\": \"Find a trending pop song.\", \"query\": \"trending pop song\"},\n",
    "    {\"input\": \"Play some 90s hits.\", \"query\": \"90s hits\"},\n",
    "    {\"input\": \"Find an acoustic version of Hotel California.\", \"query\": \"acoustic version of Hotel California\"},\n",
    "    {\"input\": \"Play a party anthem.\", \"query\": \"party anthem\"},\n",
    "    {\"input\": \"Play something by Imagine Dragons.\", \"query\": \"Imagine Dragons songs\"},\n",
    "    {\"input\": \"I want to listen to Lofi beats.\", \"query\": \"Lofi beats\"},\n",
    "    {\"input\": \"Can you play the theme song from Harry Potter?\", \"query\": \"Harry Potter theme song\"},\n",
    "    {\"input\": \"Play a motivational song.\", \"query\": \"motivational song\"},\n",
    "    {\"input\": \"Find a Tamil melody.\", \"query\": \"Tamil melody\"},\n",
    "    {\"input\": \"Play the OST from Game of Thrones.\", \"query\": \"Game of Thrones OST\"},\n",
    "    {\"input\": \"Can you play a recent K-pop hit?\", \"query\": \"recent K-pop hit\"},\n",
    "    {\"input\": \"Play the soundtrack of Titanic.\", \"query\": \"Titanic soundtrack\"}\n",
    "]\n",
    "\n",
    "\n",
    "def refine_music_query(user_input):\n",
    "    \"\"\"\n",
    "    Use LLM to extract or infer the music query from user input with enhanced accuracy.\n",
    "    \"\"\"\n",
    "    few_shot_text = \"\\n\".join([f\"Input: {ex['input']} Query: {ex['query']}\" for ex in music_few_shot_examples])\n",
    "    prompt = f\"\"\"\n",
    "        You are a music query extraction assistant. Your task is to strictly extract the specific song name and language (if mentioned) \n",
    "        from the user's input. Follow these rules:\n",
    "\n",
    "        1. Output only the song name or genre and the language (if specified).\n",
    "        2. Do not include any additional interpretation, explanation, or context.\n",
    "        3. If the input is unclear or ambiguous, return only the most relevant key terms directly related to the song or genre or print the user input directly if it is not clear.\n",
    "\n",
    "        Here are examples:\n",
    "\n",
    "        {few_shot_text}\n",
    "\n",
    "        Input: {user_input}\n",
    "        Query:\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a music query refinement assistant, specializing in accurate song identification.\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ]\n",
    "    response = llm_music.invoke(messages)\n",
    "    refined_query = response.content.strip()\n",
    "    print(f\"[DEBUG] Refined Query: {refined_query}\")\n",
    "    return refined_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Refined Query: latest song by Taylor Swift\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As of \\\\ May 2023, the latest song by Taylor Swift is \"Lavender Haze\" from her re-recorded album \"Speak Now (Taylor\\'s Version)\". This album is the third in her series of re-recorded albums, following \"Fearless (Taylor\\'s Version)\" and \"Red (Taylor\\'s Version)\". \"Lavender Haze\" is a synth-pop track that explores the intoxicating feeling of being in love.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 113, 'prompt_tokens': 13, 'total_tokens': 126, 'completion_time': 0.173860197, 'prompt_time': 0.002366817, 'queue_time': 0.02235889, 'total_time': 0.176227014}, 'model_name': 'mixtral-8x7b-32768', 'system_fingerprint': 'fp_c5f20b5bb1', 'finish_reason': 'stop', 'logprobs': None}, id='run-745819b5-24e2-4009-a36b-51613046fb75-0', usage_metadata={'input_tokens': 13, 'output_tokens': 113, 'total_tokens': 126})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(refine_music_query(\"Play the latest song by Taylor Swift.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\panka\\AppData\\Local\\Temp\\ipykernel_11032\\2738795013.py:6: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  vlc_path = \"C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\VideoLAN\"  # Replace with the actual path to your VLC installation\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "import vlc\n",
    "import os\n",
    "\n",
    "# Specify the VLC path\n",
    "vlc_path = \"C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\VideoLAN\"  # Replace with the actual path to your VLC installation\n",
    "\n",
    "# Global music player\n",
    "music_player = None\n",
    "\n",
    "def fetch_and_play_music(query):\n",
    "    \"\"\"\n",
    "    Searches for music on YouTube and streams it directly using VLC.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Configure yt-dlp to extract the streaming URL\n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'noplaylist': True,\n",
    "            'quiet': True,\n",
    "        }\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            results = ydl.extract_info(f\"ytsearch:{query}\", download=False)\n",
    "            if not results.get('entries'):\n",
    "                return \"No results found for your query. Please try a different song.\"\n",
    "\n",
    "            # Extract the first result\n",
    "            result = results['entries'][0]\n",
    "            video_title = result['title']\n",
    "            video_url = result['url']\n",
    "\n",
    "            # Stop any currently playing music\n",
    "            stop_music()\n",
    "\n",
    "            # Add headers for VLC to handle YouTube URLs\n",
    "            media = vlc.Media(video_url)\n",
    "            media.add_options(\n",
    "                \":http-user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                \"(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "                \":http-referrer=https://www.youtube.com/\"\n",
    "            )\n",
    "            # Play the stream\n",
    "            global music_player\n",
    "            # Pass the vlc_path to vlc.Instance\n",
    "            instance = vlc.Instance(f'--vlc-plugin-path={vlc_path}')\n",
    "            music_player = instance.media_player_new()\n",
    "            music_player.set_media(media)\n",
    "            music_player.audio_set_volume(100)  # Set volume to 100%\n",
    "            music_player.play()\n",
    "            music_player.set_media(media)\n",
    "            music_player.audio_set_volume(100)  # Set volume to 100%\n",
    "            music_player.play()\n",
    "\n",
    "            return f\"Playing: {video_title}. Say 'Exit' or 'Quit to stop the music.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while playing the song: {e}\"\n",
    "\n",
    "\n",
    "def stop_music():\n",
    "    \"\"\"\n",
    "    Stops the currently playing music, if any.\n",
    "    \"\"\"\n",
    "    global music_player\n",
    "    if music_player:\n",
    "        music_player.stop()\n",
    "        music_player = None\n",
    "\n",
    "\n",
    "def handle_play_music(user_input):\n",
    "    \"\"\"\n",
    "    Handles user requests for music playback.\n",
    "    \"\"\"\n",
    "    # Handle stop-related commands\n",
    "    if user_input.lower().strip() in [\"stop\", \"exit\", \"quit\"]:\n",
    "        stop_music()  # Stop the music playback\n",
    "\n",
    "    # Refine the query for playing music (if applicable)\n",
    "    refined_query = user_input.strip()  # For notebook, use raw input directly\n",
    "    if not refined_query:\n",
    "        return \"I couldn't understand the song you want to play. Could you try rephrasing?\"\n",
    "\n",
    "    # Stop any currently playing music before starting a new one\n",
    "    stop_music()\n",
    "\n",
    "    # Fetch and play the song\n",
    "    return fetch_and_play_music(refined_query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##MainCode Voice Assistant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello! Welcome to your Voice Assistant.\n",
      "Assistant: You can ask me to set reminders, fetch weather, play music, or ask general questions.\n",
      "Assistant: Say 'quit' at any time to end our session.\n",
      "Assistant: Listening...\n",
      "Assistant: Sorry, I didn't catch that. Please try again.\n",
      "Assistant: Listening...\n",
      "Assistant: Sorry, I didn't catch that. Please try again.\n",
      "Assistant: Listening...\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from datetime import datetime\n",
    "import threading\n",
    "import requests\n",
    "import yt_dlp\n",
    "import vlc\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "########################################\n",
    "# 2) Your unchanged global states & variables\n",
    "########################################\n",
    "current_functionality = None\n",
    "conversation_context = {}\n",
    "music_player = None\n",
    "\n",
    "########################################\n",
    "# 3) TTS (Text-to-Speech) Setup\n",
    "########################################\n",
    "tts_engine = pyttsx3.init()\n",
    "# Adjust speaking rate (200 is fairly normal speed)\n",
    "tts_engine.setProperty('rate', 200)\n",
    "\n",
    "def speak(text: str):\n",
    "    \"\"\"\n",
    "    Convert text to speech and also show it (like print).\n",
    "    \"\"\"\n",
    "    print(f\"Assistant: {text}\")\n",
    "    tts_engine.say(text)\n",
    "    tts_engine.runAndWait()\n",
    "\n",
    "########################################\n",
    "# 4) STT (Speech-to-Text) Setup\n",
    "########################################\n",
    "recognizer = sr.Recognizer()\n",
    "microphone = sr.Microphone()\n",
    "\n",
    "def listen_for_command() -> str:\n",
    "    \"\"\"\n",
    "    Listen via microphone and return recognized text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with microphone as source:\n",
    "            # Optional: adjust for ambient noise\n",
    "            recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "            speak(\"Listening...\")\n",
    "            audio = recognizer.listen(source)\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(f\"You: {text}\")\n",
    "        return text.strip()\n",
    "    except sr.UnknownValueError:\n",
    "        return \"\"\n",
    "    except sr.RequestError:\n",
    "        return \"\"\n",
    "\n",
    "########################################\n",
    "# 5) Your unchanged code from the question\n",
    "#    (We just copy/paste your logic exactly,\n",
    "#    so that we do not alter it.)\n",
    "########################################\n",
    "\n",
    "# -- LLM for intent detection (unchanged) --\n",
    "llm_intent = ChatGroq(\n",
    "    api_key=\"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\",\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "few_shot_examples = [\n",
    "    {\"input\": \"Can you explain what AI is?\", \"intent\": \"qna\"},\n",
    "    {\"input\": \"Remind me to call John at 3 PM.\", \"intent\": \"reminder\"},\n",
    "    {\"input\": \"What's the weather in Paris?\", \"intent\": \"weather\"},\n",
    "    {\"input\": \"Play a song from YouTube\", \"intent\": \"music\"},\n",
    "]\n",
    "\n",
    "def detect_intent(user_input):\n",
    "    \"\"\"\n",
    "    Use LLM to detect the intent of the user's query.\n",
    "    \"\"\"\n",
    "    few_shot_text = \"\\n\".join([f\"Input: {ex['input']} Intent: {ex['intent']}\" for ex in few_shot_examples])\n",
    "    prompt = f\"\"\"\n",
    "    Classify the user's query into one of these intents:\n",
    "    - qna\n",
    "    - reminder\n",
    "    - weather\n",
    "    - music\n",
    "\n",
    "    Examples:\n",
    "    {few_shot_text}\n",
    "\n",
    "    Input: {user_input}\n",
    "    Intent:\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are an intent detection assistant.\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ]\n",
    "    response = llm_intent.invoke(messages)\n",
    "    intent_detected = response.content.strip().lower()\n",
    "    print(f\"[DEBUG] Detected Intent: {intent_detected}\")\n",
    "    return intent_detected\n",
    "\n",
    "# -------------\n",
    "# Next, your process_user_input(...) from the question,\n",
    "# exactly as written, with your same logic\n",
    "# (i.e. skipping user_input if inside a functionality, etc.)\n",
    "# -------------\n",
    "def process_user_input(user_input):\n",
    "    \"\"\"\n",
    "    Route the user input to the appropriate functionality \n",
    "    based on detected intent (unchanged from your question).\n",
    "    \"\"\"\n",
    "    global current_functionality, conversation_context, music_player\n",
    "\n",
    "    # If inside a functionality, bypass intent detection\n",
    "    if current_functionality:\n",
    "        print(f\"[DEBUG] Continuing in {current_functionality} functionality.\")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            if current_functionality == \"music\" and music_player:\n",
    "                music_player.stop()\n",
    "                music_player = None\n",
    "            current_functionality = None\n",
    "            conversation_context.clear()\n",
    "            return \"Exited the current functionality. How can I assist you next?\"\n",
    "\n",
    "        # If you have Q&A, reminder, weather, etc. placeholders:\n",
    "        if current_functionality == \"qna\":\n",
    "            return handle_qna(user_input)\n",
    "        elif current_functionality == \"reminder\":\n",
    "            return handle_reminder(user_input)\n",
    "        elif current_functionality == \"weather\":\n",
    "            return handle_weather(user_input)\n",
    "        elif current_functionality == \"music\":\n",
    "            return handle_play_music(user_input)\n",
    "\n",
    "\n",
    "    # If not in any functionality, detect the intent\n",
    "    intent = detect_intent(user_input)\n",
    "    print(f\"[DEBUG] Detected Intent: {intent}\")\n",
    "\n",
    "    # Switch functionalities or default to qna\n",
    "    if intent in [\"qna\", \"reminder\", \"weather\", \"music\", \"quiz\"]:\n",
    "        current_functionality = intent\n",
    "        return process_user_input(user_input)\n",
    "    elif intent == \"qna\" or intent not in [\"reminder\", \"weather\", \"music\"]:\n",
    "        current_functionality = \"qna\"\n",
    "        return handle_qna(user_input)\n",
    "    else:\n",
    "        return \"I'm sorry, I couldn't understand that. Could you try rephrasing your request?\"\n",
    "\n",
    "########################################\n",
    "# 7) The Voice Assistant Main Loop\n",
    "########################################\n",
    "def voice_assistant():\n",
    "    \"\"\"\n",
    "    Main voice-based loop that does:\n",
    "    - TTS for greeting\n",
    "    - STT to get user input\n",
    "    - Pass user input to your existing process_user_input\n",
    "    - TTS the response\n",
    "    - Repeat until user says \"quit\"\n",
    "    \"\"\"\n",
    "    speak(\"Hello! Welcome to your Voice Assistant.\")\n",
    "    speak(\"You can ask me to set reminders, fetch weather, play music, or ask general questions.\")\n",
    "    speak(\"Say 'quit' at any time to end our session.\")\n",
    "\n",
    "    while True:\n",
    "        # Listen for user speech\n",
    "        user_input = listen_for_command()\n",
    "        if not user_input:\n",
    "            speak(\"Sorry, I didn't catch that. Please try again.\")\n",
    "            continue\n",
    "\n",
    "        # If user says 'quit'\n",
    "        if user_input.lower() == \"quit\":\n",
    "            speak(\"Goodbye! Have a great day!\")\n",
    "            break\n",
    "\n",
    "        # Otherwise, process the input\n",
    "        response = process_user_input(user_input)\n",
    "        # Speak the result\n",
    "        speak(response)\n",
    "\n",
    "\n",
    "########################################\n",
    "# 8) Entry point\n",
    "########################################\n",
    "if __name__ == \"__main__\":\n",
    "    # Just run voice assistant (no text-based chat)\n",
    "    voice_assistant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
